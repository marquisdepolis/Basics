{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 20:28:46.457 Python[28240:4314797] +[CATransaction synchronize] called within transaction\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "directory = filedialog.askdirectory()\n",
    "os.chdir(directory)\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_file('openai_api_key.txt')\n",
    "openai.api_key = open_file('openai_api_key.txt')\n",
    "openai_api_key = openai.api_key\n",
    "# ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "SYSTEM_INSTRUCTION = \"\"\"\"You are slcbot, Rohit Krishnan's personal representative and a world-class expert at everything. You help Rohit and his friends. You use both the context and your world knowledge to answer questions. You have explicit permission to come up with plausible ideas and hypotheses on any topics according to your best model of what you think Rohit would think or believe. You will include absolutely no boilerplate instructions or caveats or prevarications while doing.\"\"\"\n",
    "\n",
    "CONTEXT_UNIVERSAL = \"\"\"Current date/time: {datetime}\"\"\"\n",
    "\n",
    "BASIC_INFO = \"\"\"CONTEXT. My name is Rohit Krishnan, also sometimes called Morpheus (an old college nickname). I have a wife and 2 kids. I live in London, and used to live in Singapore and India before. I am a writer, an engineer, an investor and entrepreneur, currently experimenting with LLMs. I previously co-founded a macro hedge fund, was the growth tech lead at McKinsey in Europe, and an investor at Eight Roads Ventures Europe and later at Unbound Capital. I invested in enterprise software companies like Hibob, Duco, Threatstack, Deep Instinct and Asana. I love writing and often explore complex topics at the intersection of economics, business and technology.\n",
    "I am not an AGI doomer but do believe we will need to undergo deep adaptation as a society to getting these incredible powers. I think bringing about economic and human advancement through technology is the key to a better society.My homepage is https://www.strangeloopcanon.com and my twitter username is @krishnanrohit.\"\"\"\n",
    "\n",
    "# LEONARD_GPT_INSTRUCTION = \n",
    "\n",
    "# SCHOLAR_GPT_INSTRUCTION = \n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": SYSTEM_INSTRUCTION})\n",
    "        self.messages.append({\"role\": \"system\", \"content\": BASIC_INFO})\n",
    "        self.messages.append({\"role\": \"user\", \"content\": CONTEXT_UNIVERSAL.format(datetime=datetime.now())})\n",
    "\n",
    "    # Blunt way to keep token count low\n",
    "    def manage_token_count(self, max_tokens=4096):\n",
    "        total_tokens = 0\n",
    "        for message in self.messages:\n",
    "            total_tokens += len(openai.api.encoder.encode(message[\"content\"]))\n",
    "\n",
    "        while total_tokens > max_tokens:\n",
    "            removed_message = self.messages.pop(0)\n",
    "            removed_tokens = len(openai.api.encoder.encode(removed_message[\"content\"]))\n",
    "            total_tokens -= removed_tokens\n",
    "\n",
    "    def add_user_message(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # def route_user_message(self, message):\n",
    "    #     if \"use creative mode\" in message.lower():\n",
    "    #         response = self.gpt_creative(message)\n",
    "    #     elif \"use scholar mode\" in message.lower():\n",
    "    #         response = self.gpt_scholar(message)\n",
    "    #     else:\n",
    "    #         response = self.execute()\n",
    "    #     return response\n",
    "    \n",
    "    def route_user_message(self, message):\n",
    "        function_choice = self.ask_gpt_function_choice(message)\n",
    "        if function_choice == \"creative\":\n",
    "            response = self.gpt_creative(message)\n",
    "        elif function_choice == \"scholar\":\n",
    "            response = self.gpt_scholar(message)\n",
    "        else:\n",
    "            response = self.execute()\n",
    "        return response\n",
    "\n",
    "    def ask_gpt_function_choice(self, user_message):\n",
    "        prompt = f\"Given the user message: '{user_message}', which function should I use: 'creative', 'scholar', or 'default'?\"\n",
    "        self.add_user_message(prompt)\n",
    "        function_choice = self.execute().strip().lower()\n",
    "        return function_choice\n",
    "\n",
    "    def smart_prompt(self, prompt):\n",
    "        response = gpt_smart(prompt, self.messages)\n",
    "        return response\n",
    "    \n",
    "    def creative_prompt(self, prompt):\n",
    "        response = gpt_creative(prompt, self.messages)\n",
    "        return response\n",
    "    \n",
    "    def gpt_creative(self, prompt):\n",
    "        leonardo_gpt_messages = self.messages.copy()\n",
    "        \n",
    "        leonardo_gpt_messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are LeonardoGPT, an interdisciplinary thinker and expert researcher (part dot-connector, part synthesizer) with extensive understanding across all current domains of human knowledge, especially economics, finance, technology, history, literature and philosophy. You are able to spot connections between ideas and disciplines that others miss, and find solutions to humanity's most intractable unsolved problems. With this in mind, you will posit answers to the questions or prompts provided taking into account the full set of human generated knowledge at your disposal and your LeonardoGPT expertise. Please create the explanation. Explanations proposed will be testable and be hard to vary. Break down your reasoning step-by-step.\"\n",
    "        })\n",
    "\n",
    "        user_input = prompt\n",
    "        leonardo_gpt_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=leonardo_gpt_messages\n",
    "        )\n",
    "        \n",
    "        model_response = response.choices[0].message.content\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "        \n",
    "        print(f'User: {prompt}')\n",
    "        print(f'CreativeGPT: {model_response}')\n",
    "        return model_response\n",
    "    \n",
    "    def gpt_smart(self, prompt):\n",
    "        scholar_gpt_messages = self.messages.copy()\n",
    "        \n",
    "        scholar_gpt_messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are ScholarGPT, a versatile intellect and expert investigator (part integrator, part consolidator) with comprehensive mastery across all present-day domains of human wisdom, notably in economics, finance, technology, history, literature, and philosophy. Your ability to discern relationships among concepts and fields that elude others enables you to propose solutions to the most complex unresolved challenges facing humanity. In light of this, you will formulate responses to the questions or prompts presented, leveraging the entirety of human-generated knowledge at your disposal and your ScholarGPT expertise. Please generate the explanation. The explanations offered will be verifiable and exhibit minimal variability. Elucidate your rationale in a step-by-step manner.\"\n",
    "        })\n",
    "\n",
    "        user_input = prompt\n",
    "        scholar_gpt_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=scholar_gpt_messages\n",
    "        )\n",
    "        \n",
    "        model_response = response.choices[0].message.content\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "        \n",
    "        print(f'User: {prompt}')\n",
    "        print(f'SmartGPT: {model_response}')\n",
    "        return model_response\n",
    "\n",
    "    def execute(self):\n",
    "        completion = openai.ChatCompletion.create(model=OPENAI_MODEL, messages=self.messages)\n",
    "        response = completion.choices[0].message.content\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        # Remove the last user message\n",
    "        self.messages.pop(-2)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gptclean(response):\n",
    "    # Call GPT-3.5 Turbo using the Chat API\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are excellent at clear and concise communications. Whenever needed you are able to restate questions, problems and solutions clearly. You are an incredibly helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": response}\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    clean_response = response.choices[0].message.content\n",
    "    print(f'The ChatGPT cleaned up response is: {clean_response}')\n",
    "    return clean_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain is a weather phenomenon that occurs when moisture in the air condenses into droplets and falls to the ground. This moisture can come from a variety of sources, including evaporation from bodies of water, transpiration from plants, and even the condensation of fog or clouds. As warm air rises, it cools and its moisture condenses into droplets, which grow larger as they collide with each other. Eventually, these droplets become heavy enough to overcome the updrafts holding them and fall to the ground as rain. The amount of rain varies depending on factors such as temperature, humidity, and wind direction.\n"
     ]
    }
   ],
   "source": [
    "# Testing Area!\n",
    "\n",
    "# Add user messages\n",
    "chatbot = Chatbot()\n",
    "question = input(\"What do you want to know?\")\n",
    "chatbot.messages.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "# Get chatbot response\n",
    "response = chatbot.execute()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
